<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: coreos | Seven Story Rabbit Hole]]></title>
  <link href="http://tleyden.github.io/blog/categories/coreos/atom.xml" rel="self"/>
  <link href="http://tleyden.github.io/"/>
  <updated>2016-12-20T20:17:21-08:00</updated>
  <id>http://tleyden.github.io/</id>
  <author>
    <name><![CDATA[Traun Leyden]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Nginx proxy for Sync Gateway using Confd]]></title>
    <link href="http://tleyden.github.io/blog/2015/03/21/nginx-proxy-for-sync-gateway-using-confd/"/>
    <updated>2015-03-21T15:25:00-07:00</updated>
    <id>http://tleyden.github.io/blog/2015/03/21/nginx-proxy-for-sync-gateway-using-confd</id>
    <content type="html"><![CDATA[<p>This will walk you through setting up Sync Gateway behind nginx.  The nginx conf will be auto generated based on Sync Gateway status.</p>

<h3>Launch CoreOS instances on EC2</h3>

<p><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#cstack=sn%7ECouchbase-CoreOS%7Cturl%7Ehttp://tleyden-misc.s3.amazonaws.com/couchbase-coreos/sync_gateway.template"><img src="https://s3.amazonaws.com/cloudformation-examples/cloudformation-launch-stack.png"></a></p>

<p>Recommended values:</p>

<ul>
<li><strong>ClusterSize</strong>: 3 nodes (default)</li>
<li><strong>Discovery URL</strong>:  as it says, you need to grab a new token from <a href="https://discovery.etcd.io/new">https://discovery.etcd.io/new</a> and paste it in the box.</li>
<li><strong>KeyPair</strong>: the name of the AWS keypair you want to use.  If you haven&rsquo;t already, you&rsquo;ll want to upload your local ssh key into AWS and create a named keypair.</li>
</ul>


<h3>Wait until instances are up</h3>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/cloud-formation-create-complete.png" alt="screenshot" /></p>

<h3>ssh into a CoreOS instance</h3>

<p>Go to the AWS console under EC2 instances and find the public ip of one of your newly launched CoreOS instances.</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/ec2-instances-coreos.png" alt="screenshot" /></p>

<p>Choose any one of them (it doesn&rsquo;t matter which), and ssh into it as the <strong>core</strong> user with the cert provided in the previous step:</p>

<p><code>
$ ssh -i aws.cer -A core@ec2-54-83-80-161.compute-1.amazonaws.com
</code></p>

<h2>Spin up Sync Gateway containers</h2>

<p><code>
$ etcdctl set /couchbase.com/enable-code-refresh true
$ sudo docker run --net=host tleyden5iwx/couchbase-cluster-go update-wrapper sync-gw-cluster launch-sgw --num-nodes=2 --config-url=http://git.io/hFwa --in-memory-db
</code></p>

<h2>Verify etcd entries</h2>

<p><code>
$ etcdctl ls --recursive /
...
/couchbase.com/sync-gw-node-state
/couchbase.com/sync-gw-node-state/10.169.70.114
/couchbase.com/sync-gw-node-state/10.231.220.110
</code></p>

<h2>Create data volume container</h2>

<p><code>
$ wget https://raw.githubusercontent.com/lordelph/confd-demo/master/confdata.service
$ fleetctl start confdata.service
</code></p>

<h2>Launch sync-gateway-nginx-confd.service</h2>

<p><code>
$ wget https://raw.githubusercontent.com/lordelph/confd-demo/master/confd.service
$ sed -i -e 's/lordelph\/confd-demo/tleyden5iwx\/sync-gateway-nginx-confd/' confd.service
$ fleetctl start confd.service
</code></p>

<h2>Launch nginx service</h2>

<p><code>
$ wget https://raw.githubusercontent.com/lordelph/confd-demo/master/nginx.service
$ fleetctl start nginx.service
</code></p>

<h2>Verify</h2>

<p>Try a basic http get.</p>

<p><code>
$ nginx_ip=`fleetctl list-units | grep -i nginx | awk '{print $2}' | awk -F/ '{print $2}'`
$ curl $nginx_ip
{"couchdb":"Welcome","vendor":{"name":"Couchbase Sync Gateway","version":1},"version":"Couchbase Sync Gateway/master(a47a17f)"}
</code></p>

<p>Add &lsquo;-v&rsquo; flag to see which Sync Gateway server is servicing the request</p>

<p><code>
$ curl -v $nginx_ip
...
X-Handler: 10.231.220.110:4984
...
</code></p>

<p>If you repeat that a few more times, you should see different ip addresses for the handler.</p>

<p><strong>Take a sync gateway out of rotation</strong></p>

<p><code>
$ fleetctl stop sync_gw_node@1.service sync_gw_sidekick@1.service
</code></p>

<p>Now try hitting nginx again, and should not see the Sync Gw that you just shutdown as a handler.</p>

<p><code>
$ curl -v $nginx_ip
...
X-Handler: 10.231.220.114:4984
...
</code></p>

<p><strong>Put sync gateway back into rotation</strong></p>

<p><code>
$ fleetctl start sync_gw_node@1.service sync_gw_sidekick@1.service
</code></p>

<p>Now try hitting nginx again, and should again see the Sync Gw that you just restarted as being a handler.</p>

<p><code>
$ curl -v $nginx_ip
...
X-Handler: 10.231.220.110:4984
...
</code></p>

<h2>References</h2>

<ul>
<li><a href="http://blog.dixo.net/2015/02/load-balancing-with-coreos">http://blog.dixo.net/2015/02/load-balancing-with-coreos</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running a Sync Gateway Cluster Under CoreOS on AWS]]></title>
    <link href="http://tleyden.github.io/blog/2014/12/15/running-a-sync-gateway-cluster-under-coreos-on-aws/"/>
    <updated>2014-12-15T19:22:00-08:00</updated>
    <id>http://tleyden.github.io/blog/2014/12/15/running-a-sync-gateway-cluster-under-coreos-on-aws</id>
    <content type="html"><![CDATA[<p>The content in this blog post has <strong>moved</strong>.</p>

<p>Please go <a href="https://github.com/couchbaselabs/couchbase-server-coreos">HERE</a> to view the updated content.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running a CBFS cluster on CoreOS]]></title>
    <link href="http://tleyden.github.io/blog/2014/11/14/running-cbfs/"/>
    <updated>2014-11-14T06:43:00-08:00</updated>
    <id>http://tleyden.github.io/blog/2014/11/14/running-cbfs</id>
    <content type="html"><![CDATA[<p>This will walk you through getting a cbfs cluster up and running.</p>

<h2>What is CBFS?</h2>

<p>cbfs is a distributed filesystem on top of Couchbase Server, not unlike Mongo&rsquo;s GridFS or Riak&rsquo;s CS.</p>

<p>Here&rsquo;s a typical deployment architecture:</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/cbfs-overview.png" alt="cbfs overview" /></p>

<p>Although not shown, all cbfs daemons can communicate with all Couchbase Server instances.</p>

<p>It is not required to run cbfs on the same machine as Couchbase Server, but it <em>is</em> meant to be run in the same data center as Couchbase Server.</p>

<p>If you want a deeper understanding of how cbfs works, check the <a href="http://labs.couchbase.com/cbfs/">cbfs presentation</a> or this <a href="http://dustin.sallings.org/2012/09/27/cbfs.html">blog post</a>.</p>

<h2>Kick off a Couchbase Cluster</h2>

<p>cbfs depends on having a Couchbase cluster running.</p>

<p>Follow all of the steps in <a href="http://tleyden.github.io/blog/2014/11/01/running-couchbase-cluster-under-coreos-on-aws/">Running Couchbase Cluster Under CoreOS on AWS</a> to kick off a 3 node Couchbase cluster.</p>

<h2>Add security groups</h2>

<p>A few ports will need to be opened up for cbfs.</p>

<p>Go to the AWS console and edit the Couchbase-CoreOS-CoreOSSecurityGroup-xxxx security group and add the following rules:</p>

<p>```
Type             Protocol  Port Range Source</p>

<hr />

<p>Custom TCP Rule  TCP       8484       Custom IP: sg-6e5a0d04 (copy and paste from port 4001 rule)
Custom TCP Rule  TCP       8423       Custom IP: sg-6e5a0d04
```</p>

<p>At this point your security group should look like this:</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/security_group_cbfs.png" alt="security group" /></p>

<h1>Create a new bucket for cbfs</h1>

<p><strong>Open Couchbase Server Admin UI</strong></p>

<p>In the AWS EC2 console, find the public IP of one of the instances (it doesn&rsquo;t matter which)</p>

<p>In your browser, go to <code>http://&lt;public_ip&gt;:8091/</code></p>

<p><strong>Create Bucket</strong></p>

<p>Go to Data Buckets / Create New Bucket</p>

<p>Enter <strong>cbfs</strong> for the name of the bucket.</p>

<p>Leave all other settings as default.</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/cbfs_create_bucket.png" alt="create bucket" /></p>

<h2>ssh in</h2>

<p>In the AWS EC2 console, find the public IP of one of the instances (it doesn&rsquo;t matter which)</p>

<p>ssh into one of the machines:</p>

<p><code>
$ ssh -A core@&lt;public_ip&gt;
</code></p>

<h2>Run cbfs</h2>

<p><strong>Create a volume dir</strong></p>

<p>Since the fileystem of a docker container is not meant for high throughput io, a volume should be used for cbfs.</p>

<p>Create a directory on the host OS (i.e., on the Core OS instance)</p>

<p><code>
$ sudo mkdir -p /var/lib/cbfs/data
$ sudo chown -R core:core /var/lib/cbfs
</code></p>

<p>This will be mounted by the docker container in the next step.</p>

<p><strong>Generate fleet unit files</strong></p>

<p><code>
$ wget https://gist.githubusercontent.com/tleyden/d70161c3827cb8b788a8/raw/8f6c81f0095b0007565e9b205e90afb132552060/cbfs_node.service.template
$ for i in `seq 1 3`; do cp cbfs_node.service.template cbfs_node.$i.service; done
</code></p>

<p><strong>Start cbfs on all cluster nodes</strong></p>

<p><code>
$ fleetctl start cbfs_node.*.service
</code></p>

<p>Run <code>fleetctl list-units</code> to list the  units running in your cluster.  You should have the following:</p>

<p><code>
$ fleetctl list-units
UNIT                                            MACHINE                         ACTIVE  SUB
cbfs_node.1.service                             6ecff20c.../10.51.177.81        active  running
cbfs_node.2.service                             b8eb6653.../10.79.155.153       active  running
cbfs_node.3.service                             02d48afd.../10.186.172.24       active  running
couchbase_bootstrap_node.service                02d48afd.../10.186.172.24       active  running
couchbase_bootstrap_node_announce.service       02d48afd.../10.186.172.24       active  running
couchbase_node.1.service                        6ecff20c.../10.51.177.81        active  running
couchbase_node.2.service                        b8eb6653.../10.79.155.153       active  running
</code></p>

<p><strong>View cbfs output</strong></p>

<p><code>
$ fleetctl journal cbfs_node.1.service
2014/11/14 23:18:58 Connecting to couchbase bucket cbfs at http://10.51.177.81:8091/
2014/11/14 23:18:58 Error checking view version: MCResponse status=KEY_ENOENT, opcode=GET, opaque=0, msg: Not found
2014/11/14 23:18:58 Installing new version of views (old version=0)
2014/11/14 23:18:58 Listening to web requests on :8484 as server 10.51.177.81
2014/11/14 23:18:58 Error removing 10.51.177.81's task list: MCResponse status=KEY_ENOENT, opcode=DELETE, opaque=0, msg: Not found
2014/11/14 23:19:05 Error updating space used: Expected 1 result, got []
</code></p>

<h2>Run cbfs client</h2>

<p>Run a bash shell in a docker container that has <code>cbfsclient</code> pre-installed:</p>

<p><code>
$ sudo docker run -ti --net=host tleyden5iwx/cbfs /bin/bash
</code></p>

<p><strong>Upload a file</strong></p>

<p>From within the docker container launched in the previous step:</p>

<p>```</p>

<h1>echo &ldquo;foo&rdquo; > foo</h1>

<h1>ip=$(hostname -i | tr -d &lsquo; &rsquo;)</h1>

<h1>cbfsclient <a href="http://$ip:8484/">http://$ip:8484/</a> upload foo /foo</h1>

<p>```</p>

<p>There should be no errors.  If you run <code>fleetctl journal cbfs_node.1.service</code> again on the CoreOS instance, you should see log messages like:</p>

<p><code>
2014/11/14 21:51:43 Recorded myself as an owner of e242ed3bffccdf271b7fbaf34ed72d089537b42f: result=success
</code></p>

<p><strong>List directory</strong></p>

<p>```</p>

<h1>cbfsclient <a href="http://$ip:8484/">http://$ip:8484/</a> ls /</h1>

<p>foo
```</p>

<p>It should list the foo file we uploaded earlier.</p>

<p>Congratulations!  You now have cbfs up and running.</p>

<h2>References</h2>

<ul>
<li><a href="http://dustin.sallings.org/2012/09/27/cbfs.html">cbfs &ndash; a couchbase large object store</a></li>
<li><a href="http://labs.couchbase.com/cbfs/">cbfs presentation</a></li>
<li><a href="http://cbfs-ext.hq.couchbase.com/dist/">cbfs binary downloads</a></li>
<li><a href="http://github.com/couchbaselabs/cbfs">cbfs github repo</a></li>
<li><a href="https://github.com/couchbaselabs/cbfs/issues/132">cbfs question</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CoreOS with Nvidia CUDA GPU drivers]]></title>
    <link href="http://tleyden.github.io/blog/2014/11/04/coreos-with-nvidia-cuda-gpu-drivers/"/>
    <updated>2014-11-04T07:08:00-08:00</updated>
    <id>http://tleyden.github.io/blog/2014/11/04/coreos-with-nvidia-cuda-gpu-drivers</id>
    <content type="html"><![CDATA[<p>This will walk you through installing the Nvidia GPU kernel module and CUDA drivers on a docker container running inside of CoreOS.</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/coreos-nvidia-gpu.png" alt="architecture diagram" /></p>

<h2>Launch CoreOS on an AWS GPU instance</h2>

<ul>
<li><p>Launch a new EC2 instance</p></li>
<li><p>Under &ldquo;Community AMIs&rdquo;, search for <strong>ami-f669f29e</strong> (CoreOS stable 494.4.0 (HVM))</p></li>
<li><p>Select the GPU instances: <strong>g2.2xlarge</strong></p></li>
<li><p>Increase root EBS store from 8 GB &ndash;> 20 GB to give yourself some breathing room</p></li>
</ul>


<h2>ssh into CoreOS instance</h2>

<p>Find the public ip of the EC2 instance launched above, and ssh into it:</p>

<p><code>
$ ssh -A core@ec2-54-80-24-46.compute-1.amazonaws.com
</code></p>

<h2>Run Ubuntu 14 docker container in privileged mode</h2>

<p><code>
$ sudo docker run --privileged=true -i -t ubuntu:14.04 /bin/bash
</code></p>

<p>After the above command, you should be inside a root shell in your docker container.  The rest of the steps will assume this.</p>

<h2>Install build tools + other required packages</h2>

<p>In order to match the version of gcc that was used to build the CoreOS kernel.  (gcc 4.7)</p>

<p>```</p>

<h1>apt-get update</h1>

<h1>apt-get install gcc-4.7 g++-4.7 wget git make dpkg-dev</h1>

<p>```</p>

<p><strong>Set gcc 4.7 as default</strong></p>

<p>```</p>

<h1>update-alternatives &mdash;remove gcc /usr/bin/gcc-4.8</h1>

<h1>update-alternatives &mdash;install /usr/bin/gcc gcc /usr/bin/gcc-4.7 60 &mdash;slave /usr/bin/g++ g++ /usr/bin/g++-4.7</h1>

<h1>update-alternatives &mdash;install /usr/bin/gcc gcc /usr/bin/gcc-4.8 40 &mdash;slave /usr/bin/g++ g++ /usr/bin/g++-4.8</h1>

<p>```</p>

<p><strong>Verify</strong></p>

<p>```</p>

<h1>update-alternatives &mdash;config gcc</h1>

<p>```</p>

<p>It should list gcc 4.7 with an asterisk next to it:</p>

<p><code>
* 0            /usr/bin/gcc-4.7   60        auto mode
</code></p>

<h2>Prepare CoreOS kernel source</h2>

<p><strong>Clone CoreOS kernel repository</strong></p>

<p><code>
$ mkdir -p /usr/src/kernels
$ cd /usr/src/kernels
$ git clone https://github.com/coreos/linux.git
</code></p>

<p><strong>Find CoreOS kernel version</strong></p>

<p>```</p>

<h1>uname -a</h1>

<p>Linux ip-10-11-167-200.ec2.internal 3.17.2+ #2 SMP Tue Nov 4 04:15:48 UTC 2014 x86_64 Intel&reg; Xeon&reg; CPU E5-2670 0 @ 2.60GHz GenuineIntel GNU/Linux
```</p>

<p>The CoreOS kernel version is <strong>3.17.2</strong></p>

<p><strong>Switch correct branch for this kernel version </strong></p>

<p>```</p>

<h1>cd linux</h1>

<h1>git checkout remotes/origin/coreos/v3.17.2</h1>

<p>```</p>

<p><strong>Create kernel configuration file</strong></p>

<p>```</p>

<h1>zcat /proc/config.gz > /usr/src/kernels/linux/.config</h1>

<p>```</p>

<p><strong>Prepare kernel source for building modules</strong></p>

<p>```</p>

<h1>make modules_prepare</h1>

<p>```</p>

<p>Now you should be ready to install the nvidia driver.</p>

<p><strong>Hack the kernel version</strong></p>

<p>In order to avoid <a href="https://gist.github.com/tleyden/2a46a86056e476976a8e#file-gistfile1-txt-L956">nvidia: version magic errors</a>, the following hack is required:</p>

<p>```</p>

<h1>sed -i -e &rsquo;s/3.17.2/3.17.2+/&lsquo; include/generated/utsrelease.h</h1>

<p>```</p>

<p>I&rsquo;ve <a href="https://groups.google.com/d/msg/coreos-user/CSp_wSywmI4/CBHwocj8v9oJ">posted to the CoreOS Group</a> to ask why this hack is needed.</p>

<h2>Install nvidia driver</h2>

<p><strong>Download</strong></p>

<p>```</p>

<h1>mkdir -p /opt/nvidia</h1>

<h1>cd /opt/nvidia</h1>

<h1>wget <a href="http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run">http://developer.download.nvidia.com/compute/cuda/6_5/rel/installers/cuda_6.5.14_linux_64.run</a></h1>

<p>```</p>

<p><strong>Unpack</strong></p>

<p>```</p>

<h1>chmod +x cuda_6.5.14_linux_64.run</h1>

<h1>mkdir nvidia_installers</h1>

<h1>./cuda_6.5.14_linux_64.run -extract=<code>pwd</code>/nvidia_installers</h1>

<p>```</p>

<p><strong>Install</strong></p>

<p>```</p>

<h1>cd nvidia_installers</h1>

<h1>./NVIDIA-Linux-x86_64-340.29.run &mdash;kernel-source-path=/usr/src/kernels/linux/</h1>

<p>```</p>

<p><strong>Installer Questions</strong></p>

<ul>
<li>Install NVidia&rsquo;s 32-bit compatibility libraries? <strong>YES</strong></li>
<li>Would you like to run nvidia-xconfig? <strong>NO</strong></li>
</ul>


<p>If everything worked, you should see:</p>

<p><img src="http://tleyden-misc.s3.amazonaws.com/blog_images/nvidia_driver_installed.png" alt="nvidia drivers installed" /></p>

<p>your <code>/var/log/nvidia-installer.log</code> should look something like <a href="https://gist.github.com/tleyden/6d585fb8ab08154949c8">this</a></p>

<h2>Load nvidia kernel module</h2>

<p>```</p>

<h1>modprobe nvidia</h1>

<p>```</p>

<p>No errors should be returned.  Verify it&rsquo;s loaded by running:</p>

<p>```</p>

<h1>lsmod | grep -i nvidia</h1>

<p>```</p>

<p>and you should see:</p>

<p><code>
nvidia              10533711  0
i2c_core               41189  2 nvidia,i2c_piix4
</code></p>

<h2>Install CUDA</h2>

<p>In order to fully verify that the kernel module is working correctly, install the CUDA drivers + library and run a device query.</p>

<p>To install CUDA:</p>

<p>```</p>

<h1>./cuda-linux64-rel-6.5.14-18749181.run</h1>

<h1>./cuda-samples-linux-6.5.14-18745345.run</h1>

<p>```</p>

<h2>Verify CUDA</h2>

<p>```</p>

<h1>cd /usr/local/cuda/samples/1_Utilities/deviceQuery</h1>

<h1>make</h1>

<h1>./deviceQuery</h1>

<p>```</p>

<p>You should see the following output:</p>

<p><code>
deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 6.5, CUDA Runtime Version = 6.5, NumDevs = 1, Device0 = GRID K520
Result = PASS
</code></p>

<p>Congratulations!  You now have a docker container running under CoreOS that can access the GPU.</p>

<h1>Appendix: Expose GPU to other docker containers</h1>

<p>If you need <em>other</em> docker containers on this CoreOS instance to be able to access the GPU, you can do the following steps.</p>

<p><strong>Exit docker container</strong></p>

<p>```</p>

<h1>exit</h1>

<p>```</p>

<p>You should be back to your CoreOS shell.</p>

<p><strong>Add nvidia device nodes</strong></p>

<p><code>
$ wget https://gist.githubusercontent.com/tleyden/74f593a0beea300de08c/raw/95ed93c5751a989e58153db6f88c35515b7af120/nvidia_devices.sh
$ chmod +x nvidia_devices.sh
$ sudo ./nvidia_devices.sh
</code></p>

<p><strong>Verify device nodes</strong></p>

<p><code>
$ ls -alh /dev | grep -i nvidia
crw-rw-rw-  1 root root  251,   0 Nov  5 16:37 nvidia-uvm
crw-rw-rw-  1 root root  195,   0 Nov  5 16:37 nvidia0
crw-rw-rw-  1 root root  195, 255 Nov  5 16:37 nvidiactl
</code></p>

<p><strong>Launch docker containers</strong></p>

<p>When you launch other docker containers on the same CoreOS instance, to allow them to access the GPU device you will need to add the following arguments:</p>

<p><code>
$ sudo docker run -ti --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm tleyden5iwx/ubuntu-cuda /bin/bash
</code></p>

<h2>References</h2>

<ul>
<li><a href="https://github.com/tleyden/tleyden.github.io/blob/6d71759cc5e530efcae10d9c6012dd217f76795c/source/_posts/2014-11-04-coreos-with-nvidia-cuda-gpu-drivers.markdown">Previous version of this blog post</a></li>
<li><a href="https://groups.google.com/forum/#!topic/coreos-user/CSp_wSywmI4">CoreOS Google Group thread</a> &ndash; Thanks Сергей!</li>
<li><a href="http://tleyden.github.io/blog/2014/10/25/docker-on-aws-gpu-ubuntu-14-dot-04-slash-cuda-6-dot-5/">Docker on AWS GPU Ubuntu 14.04 / CUDA 6.5</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Couchbase Cluster Under CoreOS on AWS]]></title>
    <link href="http://tleyden.github.io/blog/2014/11/01/running-couchbase-cluster-under-coreos-on-aws/"/>
    <updated>2014-11-01T12:16:00-07:00</updated>
    <id>http://tleyden.github.io/blog/2014/11/01/running-couchbase-cluster-under-coreos-on-aws</id>
    <content type="html"><![CDATA[<p>The content in this blog post has <strong>moved</strong>.</p>

<p>Please go <a href="https://github.com/couchbaselabs/couchbase-server-coreos">HERE</a> to view the updated content.</p>
]]></content>
  </entry>
  
</feed>
